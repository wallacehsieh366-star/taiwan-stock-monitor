# -*- coding: utf-8 -*-
import os
import time
import threading
import requests
import pandas as pd
import yfinance as yf
import concurrent.futures
from io import StringIO
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from pathlib import Path

# ========== æ ¸å¿ƒåƒæ•¸è¨­å®š ==========
MARKET_CODE = "tw-share"
DATA_SUBDIR = "dayK"
PROJECT_NAME = "å°è‚¡æ—¥Kè³‡æ–™ä¸‹è¼‰å™¨"

# è·¯å¾‘è¨­å®šï¼šç¢ºä¿ç›¸å°æ–¼å°ˆæ¡ˆç›®éŒ„
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data", MARKET_CODE, DATA_SUBDIR)
LOG_DIR = os.path.join(BASE_DIR, "logs", PROJECT_NAME)
CKPT_FILE = os.path.join(LOG_DIR, "checkpoint_tw.csv")

MAX_WORKERS = 8       # ä¸‹è¼‰åŸ·è¡Œç·’æ•¸é‡
MIN_FILE_SIZE = 100   # æœ‰æ•ˆæª”æ¡ˆæœ€å°ä½å…ƒçµ„
AUTO_ADJUST = False   # yfinance åƒ¹æ ¼èª¿æ•´

# ç¢ºä¿ç›®éŒ„å­˜åœ¨
Path(DATA_DIR).mkdir(parents=True, exist_ok=True)
Path(LOG_DIR).mkdir(parents=True, exist_ok=True)

def log(msg: str):
    now = pd.Timestamp.now()
    print(f"{now:%H:%M:%S}: {msg}")

def safe_filename(s: str) -> str:
    return (s.replace("/", "_").replace("\\", "_").replace(":", "_")
              .replace("*", "_").replace("?", "_").replace('"', "_")
              .replace("<", "_").replace(">", "_").replace("|", "_"))

def parse_item(item: str):
    """è§£æ 'ä»£è™Ÿ&åç¨±' æ ¼å¼"""
    if '&' in item:
        tkr, nm = item.split('&', 1)
    else:
        tkr, nm = item.strip(), "æœªçŸ¥è‚¡ç¥¨"
    return tkr.strip(), nm.strip()

def get_full_stock_list():
    """
    å°ˆæ¥­ç‰ˆçˆ¬èŸ²ï¼šå¾è­‰äº¤æ‰€æŠ“å–å…¨å¸‚å ´è‚¡ç¥¨æ¸…å–® (å«ä¸Šå¸‚ã€ä¸Šæ«ƒã€å‰µæ–°æ¿ã€ETF)
    """
    url_configs = [
        {'name': 'listed', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?market=1&issuetype=1&Page=1&chklike=Y', 'suffix': '.TW'},
        {'name': 'otc', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?market=2&issuetype=4&Page=1&chklike=Y', 'suffix': '.TWO'},
        {'name': 'etf', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?owncode=&stockname=&isincode=&market=1&issuetype=I&industry_code=&Page=1&chklike=Y', 'suffix': '.TW'},
        {'name': 'tw_innovation', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?owncode=&stockname=&isincode=&market=C&issuetype=C&industry_code=&Page=1&chklike=Y', 'suffix': '.TW'},
        {'name': 'otc_innovation', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?owncode=&stockname=&isincode=&market=A&issuetype=C&industry_code=&Page=1&chklike=Y', 'suffix': '.TWO'},
    ]

    all_stock_names = []
    
    def fetch_api(config):
        try:
            time.sleep(0.3)
            resp = requests.get(config['url'], timeout=15)
            df = pd.read_html(StringIO(resp.text), header=0)[0]
            items = []
            for _, row in df.iterrows():
                code = str(row['æœ‰åƒ¹è­‰åˆ¸ä»£è™Ÿ']).strip()
                name = str(row['æœ‰åƒ¹è­‰åˆ¸åç¨±']).strip()
                # éæ¿¾æ‰æ¬Šè­‰èˆ‡éè‚¡ç¥¨é¡ï¼ˆä»£è™Ÿé€šå¸¸ > 5 ç¢¼ï¼‰
                if code and len(code) <= 5:
                    items.append(f"{code}&{name}")
            return items
        except Exception as e:
            print(f"âŒ æŠ“å– {config['name']} å¤±æ•—: {e}")
            return []

    log("ğŸŒ å•Ÿå‹•å¤šåŸ·è¡Œç·’çˆ¬èŸ²ç²å–æœ€æ–°å°è‚¡åå–®...")
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(fetch_api, cfg) for cfg in url_configs]
        for f in concurrent.futures.as_completed(futures):
            all_stock_names.extend(f.result())

    final_list = list(set(all_stock_names))
    log(f"âœ… æˆåŠŸç²å–å…¨å¸‚å ´æ¸…å–®ï¼šå…± {len(final_list)} æª”æ¨™çš„")
    return final_list

def build_checkpoint(items):
    rows = []
    for it in items:
        tkr, nm = parse_item(it)
        out_path = os.path.join(DATA_DIR, f"{tkr}_{safe_filename(nm)}.csv")
        status = "skipped" if os.path.exists(out_path) and os.path.getsize(out_path) > MIN_FILE_SIZE else "pending"
        rows.append((tkr, nm, status, ""))
    df = pd.DataFrame(rows, columns=["ticker", "name", "status", "last_error"])
    df.to_csv(CKPT_FILE, index=False, encoding='utf-8-sig')
    return df

def download_stock_data(row):
    ticker_id, name = row["ticker"], row["name"]
    # è‡ªå‹•è£œè¶³ yfinance å¾Œç¶´
    yf_ticker = ticker_id
    if ".TW" not in yf_ticker.upper() and ".TWO" not in yf_ticker.upper():
        # ç°¡å–®åˆ¤å®šï¼šä¸€èˆ¬ä¸Šå¸‚è‚¡ç¥¨ 4 ç¢¼è£œ .TWï¼Œé€™éƒ¨åˆ†ç”± get_full_stock_list è™•ç†æ›´å¥½
        # ä½†é€™è£¡åŠ å…¥ä¸€å€‹ä¿éšªæ©Ÿåˆ¶
        yf_ticker = f"{ticker_id}.TW" 

    try:
        out_path = os.path.join(DATA_DIR, f"{ticker_id}_{safe_filename(name)}.csv")
        if os.path.exists(out_path) and os.path.getsize(out_path) > MIN_FILE_SIZE:
            return {"ticker": ticker_id, "status": "skipped", "err": ""}

        tk = yf.Ticker(yf_ticker)
        hist = tk.history(period="2y", auto_adjust=AUTO_ADJUST)

        if hist is None or hist.empty:
            # é‡å°ä¸‹å¸‚æ¨™çš„ï¼Œæˆ‘å€‘ä¹Ÿæ¨™è¨˜ç‚º skipped é¿å…é‡è¤‡æŠ“å–æµªè²»æ™‚é–“
            return {"ticker": ticker_id, "status": "skipped", "err": "empty_data"}

        hist.reset_index(inplace=True)
        hist.columns = [c.lower() for c in hist.columns]
        hist.to_csv(out_path, index=False, encoding='utf-8-sig')
        return {"ticker": ticker_id, "status": "success", "err": ""}

    except Exception as e:
        return {"ticker": ticker_id, "status": "failed", "err": str(e)}

def main():
    """ä¸»é€²å…¥é»"""
    stockname_list = get_full_stock_list()
    
    if not stockname_list and os.path.exists(CKPT_FILE):
        ckpt = pd.read_csv(CKPT_FILE)
        log(f"ğŸ” è¼‰å…¥æ—¢æœ‰çºŒå‚³é»ï¼š{len(ckpt)} æª”")
    elif not stockname_list:
        log("âŒ ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®ä¸”ç„¡çºŒå‚³ç´€éŒ„ï¼Œçµ‚æ­¢åŸ·è¡Œã€‚")
        return
    else:
        # å¦‚æœæœ‰æ–°æŠ“åˆ°çš„æ¸…å–®ï¼Œå‰‡å»ºç«‹/æ›´æ–° Checkpoint
        ckpt = build_checkpoint(stockname_list)
        log(f"ğŸ†• å·²åŒæ­¥æœ€æ–°æ¸…å–®ï¼Œé–‹å§‹æª¢æŸ¥ä¸‹è¼‰ç‹€æ…‹...")

    todo = ckpt[ckpt["status"].isin(["pending", "failed"])].copy()
    
    if len(todo) == 0:
        log("ğŸ‰ å°è‚¡æ•¸æ“šå·²å°±ç·’ï¼Œç„¡éœ€ä¸‹è¼‰ã€‚")
        return

    log(f"ğŸš€ é–‹å§‹ä¸‹è¼‰ {len(todo)} æ”¯æ¨™çš„æ—¥Kè³‡æ–™...")
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_row = {executor.submit(download_stock_data, r): r for _, r in todo.iterrows()}
        pbar = tqdm(total=len(todo), desc="ä¸‹è¼‰é€²åº¦")
        
        for future in as_completed(future_to_row):
            res = future.result()
            mask = (ckpt["ticker"] == res["ticker"])
            ckpt.loc[mask, ["status", "last_error"]] = [res["status"], res["err"]]
            # æ¯ 10 æª”æ›´æ–°ä¸€æ¬¡ CSV æª”æ¡ˆï¼Œé¿å…æ„å¤–ä¸­æ–·ä¸Ÿå¤±ç´€éŒ„
            if pbar.n % 10 == 0:
                ckpt.to_csv(CKPT_FILE, index=False, encoding='utf-8-sig')
            pbar.update(1)
        pbar.close()

    ckpt.to_csv(CKPT_FILE, index=False, encoding='utf-8-sig')
    log("ğŸ“Š ä¸‹è¼‰ä»»å‹™åŸ·è¡Œå®Œç•¢ã€‚")

if __name__ == "__main__":
    main()
